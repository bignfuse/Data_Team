{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43deba0e-f245-4406-bab8-021bf1f45db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@1.627] global /io/opencv_contrib/modules/xfeatures2d/misc/python/shadow_sift.hpp (13) SIFT_create DEPRECATED: cv.xfeatures2d.SIFT_create() is deprecated due SIFT tranfer to the main repository. https://github.com/opencv/opencv/issues/16736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_data/CAP-0000000000000000078.pdf', 'input_data/CAP-0000000000000000148.pdf', 'input_data/CAP-0000000000000000016.pdf', 'input_data/CAP-0000000000000000111.pdf', 'input_data/CAP-0000000000000000124.pdf', 'input_data/CAP-0000000000000000083.pdf', 'input_data/CAP-0000000000000000163.pdf', 'input_data/CAP-0000000000000000099.pdf', 'input_data/CAP-0000000000000000043.pdf', 'input_data/CAP-0000000000000000045.pdf', 'input_data/CAP-0000000000000000152.pdf', 'input_data/CAP-0000000000000000106.pdf', 'input_data/CAP-0000000000000000080.pdf', 'input_data/CAP-0000000000000000064.pdf', 'input_data/CAP-0000000000000000015.pdf', 'input_data/CAP-0000000000000000169.pdf', 'input_data/CAP-0000000000000000116.pdf', 'input_data/CAP-0000000000000000072.pdf', 'input_data/CAP-0000000000000000014.pdf', 'input_data/CAP-0000000000000000154.pdf', 'input_data/CAP-0000000000000000109.pdf', 'input_data/CAP-0000000000000000077.pdf', 'input_data/CAP-0000000000000000149.pdf', 'input_data/CAP-0000000000000000050.pdf', 'input_data/CAP-0000000000000000047.pdf', 'input_data/CAP-0000000000000000054.pdf', 'input_data/CAP-0000000000000000121.pdf', 'input_data/CAP-0000000000000000086.pdf', 'input_data/CAP-0000000000000000035.pdf', 'input_data/CAP-0000000000000000084.pdf', 'input_data/CAP-0000000000000000166.pdf', 'input_data/CAP-0000000000000000174.pdf', 'input_data/CAP-0000000000000000167.pdf', 'input_data/CAP-0000000000000000073.pdf', 'input_data/CAP-0000000000000000053.pdf', 'input_data/CAP-0000000000000000110.pdf', 'input_data/CAP-0000000000000000041.pdf', 'input_data/CAP-0000000000000000017.pdf', 'input_data/CAP-0000000000000000006.pdf', 'input_data/CAP-0000000000000000168.pdf']\n",
      "---------------------Splitting Pdf---------------------\n",
      "saved_pdf_images/CAP-0000000000000000080/\n",
      "input_data/CAP-0000000000000000080.pdf\n",
      "-------------Image saved at:: saved_pdf_images/CAP-0000000000000000080/1.jpg\n",
      "-------------Image saved at:: saved_pdf_images/CAP-0000000000000000080/2.jpg\n",
      "-------------Image saved at:: saved_pdf_images/CAP-0000000000000000080/3.jpg\n",
      "-------------Image saved at:: saved_pdf_images/CAP-0000000000000000080/4.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 17:43:36.786326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-29 17:43:36.791971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/bigyan/anaconda3/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-08-29 17:43:36.791996: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-08-29 17:43:36.792383: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 332ms/step\n",
      "1/1 [==============================] - 0s 146ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "35/35 [==============================] - 0s 4ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "---------------------Aligning Image---------------------\n",
      "---------------------Cropping image ---------------------\n",
      "---------------------Aligning Image---------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     pdf_image_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(saved_pdf,c)\n\u001b[0;32m---> 43\u001b[0m     aligned_img\u001b[38;5;241m=\u001b[39m\u001b[43malignImages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mform_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/template_image/template_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     save_cropped_image(aligned_img,pdf_image_path,std_json_path,key_json_path,form_type)\n\u001b[1;32m     45\u001b[0m data\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/final_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/Fusemachine/NIC/folders_used_for_test/Data_team_crop_map_API/align.py:23\u001b[0m, in \u001b[0;36malignImages\u001b[0;34m(img_path, template_path, file_id, validate_form)\u001b[0m\n\u001b[1;32m     19\u001b[0m kp2, dec2 \u001b[38;5;241m=\u001b[39m orb\u001b[38;5;241m.\u001b[39mdetectAndCompute(img1_gray, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# bf = cv2.BFMatcher()\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mknnMatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdec1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdec2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m good \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m,n \u001b[38;5;129;01min\u001b[39;00m matches:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from crop import save_cropped_image\n",
    "from file_utils import split_and_save_pdf_images,is_new_form\n",
    "import os\n",
    "from align import alignImages\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "pdf_path=\"input_data\"\n",
    "from time import time\n",
    "\n",
    "list_pdf=glob(pdf_path+\"/*.pdf\")\n",
    "print(list_pdf)\n",
    "if os.path.isfile(\"label.txt\"):\n",
    "    with open(\"label.txt\",\"r\") as read_txt:\n",
    "        f=read_txt.readlines()\n",
    "        lines=[l.split(\"/\")[1] for l in f]\n",
    "        last_file=f\"input_data/{lines[-1]}.pdf\"\n",
    "        start=list_pdf.index(last_file)\n",
    "        \n",
    "else:\n",
    "    start=-1\n",
    "\n",
    "label=open(\"label.txt\",\"a+\")\n",
    "\n",
    "\n",
    "for p in list_pdf[start+1:]:\n",
    "    t1=time()\n",
    "    saved_pdf=split_and_save_pdf_images(p)\n",
    "    unique_id= p.split('/')[-1].split('.')[0]\n",
    "    page_3_img_path = os.path.join(saved_pdf,\"3.jpg\")\n",
    "    form_type= is_new_form(page_3_img_path)\n",
    "    if form_type== True:\n",
    "        form_type=\"new\"\n",
    "        std_json_path=f\"{form_type}/standard_json_files/\"\n",
    "        key_json_path=f\"{form_type}/key_value_mapping_json_files/\"\n",
    "    elif form_type==False:\n",
    "        form_type=\"old\"\n",
    "        std_json_path=f\"{form_type}/standard_json_files/\"\n",
    "        key_json_path=f\"{form_type}/key_value_mapping_json_files/\"\n",
    "    for n,c in enumerate(os.listdir(saved_pdf)):\n",
    "        if n>2:\n",
    "            break\n",
    "        pdf_image_path=os.path.join(saved_pdf,c)\n",
    "        aligned_img=alignImages(pdf_image_path,f\"{form_type}/template_image/template_{c.split('.')[0]}.jpg\")\n",
    "        save_cropped_image(aligned_img,pdf_image_path,std_json_path,key_json_path,form_type)\n",
    "    data=pd.read_csv(f\"{pdf_path}/final_data.csv\")\n",
    "    if data.index.name != \"UniequeId\":\n",
    "        data=data.set_index(\"UniequeId\")\n",
    "    crop_dir=f\"{form_type}_cropped/{unique_id}\"\n",
    "    in_name=0\n",
    "    key_in=[]\n",
    "    for crop in os.listdir(crop_dir):\n",
    "        key_name=crop.split(\"_\")\n",
    "        if len(key_name)>2:\n",
    "            key_name='_'.join(key_name[1:len(key_name)]).split(\".\")[0]\n",
    "        else:\n",
    "            key_name= key_name[-1].split(\".\")[0]\n",
    "        if(key_name in list(data.columns)):\n",
    "            key_in.append(key_name)\n",
    "            values=data.loc[unique_id,key_name]\n",
    "            if type(values)== str:\n",
    "                values=values.title()\n",
    "            label.write(f\"{crop_dir}/{crop} {values}\\n\")\n",
    "        else:\n",
    "            label.write(f\"{crop_dir}/{crop} check\\n\")\n",
    "    print(\"remaining: \",list(set(data.columns) - set(key_in)))\n",
    "    print(\"Total time taken:\",time()-t1)\n",
    "            \n",
    "label.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3053abcf-7c9b-445d-934d-b7897d9813a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Distict & Municipality.xlsx', sheet_name=None)  \n",
    "for key,values in df.items(): \n",
    "    df[key].to_csv('Test/data_%s.csv'%key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d342058-504a-49c8-a511-a805e2d8c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "old_csv=pd.read_csv(f\"Test/input_fields.csv\")\n",
    "dit_csv=pd.read_csv(\"Test/data_District.csv\")\n",
    "\n",
    "code_map=dit_csv.set_index('District Code').to_dict()['District']\n",
    "\n",
    "dist_ls=[\"Communication_Address_District\",\"Permanent_Address_District\",\"Identification_Document_Issue_Place_1\"]\n",
    "for dis in dist_ls:\n",
    "    ch_dist=[]\n",
    "    for d in old_csv[dis]:\n",
    "        if d in code_map.keys():\n",
    "            ch_dist.append(code_map[d])\n",
    "        else:\n",
    "            ch_dist.append(d)\n",
    "        \n",
    "    old_csv[dis]=ch_dist\n",
    "old_csv.to_csv(\"final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee21c376-f622-4886-88bc-aa5a9455ec29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACHHA': 'ACHHAM',\n",
       " 'ARGHA': 'ARGHAKHANCHI',\n",
       " 'BAGLU': 'BAGLUNG',\n",
       " 'BAITA': 'BAITADI',\n",
       " 'BAJHA': 'BAJHANG',\n",
       " 'BAJUR': 'BAJURA',\n",
       " 'BANKE': 'BANKE',\n",
       " 'BARA': 'BARA',\n",
       " 'BARDI': 'BARDIYA',\n",
       " 'BHAKT': 'BHAKTAPUR',\n",
       " 'BHOJP': 'BHOJPUR',\n",
       " 'CHITW': 'CHITWAN',\n",
       " 'DADEL': 'DADELDHURA',\n",
       " 'DAILE': 'DAILEKH',\n",
       " 'DANG': 'DANG',\n",
       " 'DARCH': 'DARCHULA',\n",
       " 'DHADI': 'DHADING',\n",
       " 'DHANK': 'DHANKUTA',\n",
       " 'DHANU': 'DHANUSHA',\n",
       " 'DOLKH': 'DOLAKHA',\n",
       " 'DOLPA': 'DOLPA',\n",
       " 'DOTI': 'DOTI',\n",
       " 'GORKH': 'GORKHA',\n",
       " 'GULMI': 'GULMI',\n",
       " 'HUMLA': 'HUMLA',\n",
       " 'ILAM': 'ILAM',\n",
       " 'JAJAR': 'JAJARKOT',\n",
       " 'JHAPA': 'JHAPA',\n",
       " 'JUMLA': 'JUMLA',\n",
       " 'KAILA': 'KAILALI',\n",
       " 'KALIK': 'KALIKOT',\n",
       " 'KANCH': 'KANCHANPUR',\n",
       " 'KAPIL': 'KAPILVASTU',\n",
       " 'KASKI': 'KASKI',\n",
       " 'KATHM': 'KATHMANDU',\n",
       " 'KAVRE': 'KAVREPALANCHOK',\n",
       " 'KHOTA': 'KHOTANG',\n",
       " 'LALIT': 'LALITPUR',\n",
       " 'LAMJU': 'LAMJUNG',\n",
       " 'MAHOT': 'MAHOTTARI',\n",
       " 'MAKWA': 'MAKWANPUR',\n",
       " 'MANAG': 'MANAG',\n",
       " 'MORAN': 'MORANG',\n",
       " 'MUGU': 'MUGU',\n",
       " 'MUSTA': 'MUSTANG',\n",
       " 'MYAGD': 'MYAGDI',\n",
       " nan: nan,\n",
       " 'NAWAL': 'NAWALPARASI',\n",
       " 'NAWEA': 'NAWALPARASI EAST',\n",
       " 'NAWWE': 'NAWALPARASI WEST',\n",
       " 'NUWAK': 'NUWAKOT',\n",
       " 'OKHAL': 'OKHALDHUNGA',\n",
       " 'OTHER': 'NOT AVAILABLE',\n",
       " 'PALPA': 'PALPA',\n",
       " 'PANCH': 'PANCHTHAR',\n",
       " 'PARSA': 'PARSA',\n",
       " 'PARWA': 'PARBAT',\n",
       " 'PYUTH': 'PYUTHAN',\n",
       " 'RAMEC': 'RAMECHHAP',\n",
       " 'RASUW': 'RASUWA',\n",
       " 'RAUTH': 'RAUTHAHAT',\n",
       " 'ROLPA': 'ROLPA',\n",
       " 'RUKEA': 'RUKUM EAST',\n",
       " 'RUKUM': 'RUKUM',\n",
       " 'RUKWE': 'RUKUM WEST',\n",
       " 'RUPAN': 'RUPANDEHI',\n",
       " 'SALYA': 'SALYAN',\n",
       " 'SANKH': 'SANKHUWASABHA',\n",
       " 'SAPTA': 'SAPTARI',\n",
       " 'SARLA': 'SARLAHI',\n",
       " 'SIND': 'SINDHUPALCHOK',\n",
       " 'SINDH': 'SINDHULI',\n",
       " 'SIRAH': 'SIRAHA',\n",
       " 'SOLUK': 'SOLUKHUMBU',\n",
       " 'SUNSA': 'SUNSARI',\n",
       " 'SURKH': 'SURKHET',\n",
       " 'SYANG': 'SYANGJA',\n",
       " 'TANAH': 'TANAHUN',\n",
       " 'TAPLE': 'TAPLEJUNG',\n",
       " 'TERHA': 'TERHATHUM',\n",
       " 'UDAYP': 'UDAYPUR'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dit_csv=pd.read_csv(\"Test/data_District.csv\")\n",
    "\n",
    "code_map=dit_csv.set_index('District Code').to_dict()['District']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9fd632-466b-4bbc-af3b-54627bf2dfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
